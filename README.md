# Object Recognition Application With Mobile Phone For The Visually Impaired

I am developing a mobile application for visually impaired people.

The application gives an introduction about how to use it with voice on first use. I used the phone screen as two parts. The microphone is at the top and the camera button is at the bottom.

After the user touches the top of the screen, that is, the microphone, and says the object he wants to search for with a voice command, the camera is opened and the searched object is tried to be found. If the searched object is found, a return is provided as 'the searched object was found'.

When the bottom of the screen is touched, the camera starts and the name of the objects around is told to the user.

Feel free to contribute to the project and provide feedback by sending a pull request.

![Screenshot_20220507-143753](https://user-images.githubusercontent.com/55411723/167252946-74e6e37c-322b-4ef5-91d0-327c36965eea.png)
![Screenshot_20220507-143726](https://user-images.githubusercontent.com/55411723/167252949-39bee8c6-7e09-458e-b203-687e164732f7.png)
![Screenshot_20220507-143411](https://user-images.githubusercontent.com/55411723/167252952-e89e5cba-7a33-402c-b780-239b78a74378.png)
![Screenshot_20220507-143323](https://user-images.githubusercontent.com/55411723/167252959-5080f801-d9f7-46da-b57b-1ed57eae1028.png)
![Screenshot_20220507-143618](https://user-images.githubusercontent.com/55411723/167252968-bd877357-dc1b-4b3a-9d5a-bc208c339cc9.png)
